---
title: Speakers and Program
indexing: false
sitemap: false
---
### Invited Speakers

##### Alphabetical order on surname (Click name for Biography)   
  * <Details><summary>►Moritz Bächer (Disney Research, Switzerland)</summary><table width="100%"><tr><td width="25%"> <img src="../assets/images/moritz_baecher.jpeg" alt= "" width="300" style="vertical-align: left;"></td><td width="5%"></td><td width="70%" style="vertical-align: left; font-size: 75%;"> Moritz Bächer is the Associate Lab Director of Disney Research at Walt Disney Imagineering, where he leads a strategic program focusing on the development of novel model- and learning-based tools for the design and control of believable robotic characters. His core expertise is the optimal design and control of both soft and rigid systems, using a combination of differentiable simulation and reinforcement learning. Prior to joining Disney, he received his Ph.D. from the Harvard School of Engineering and Applied Sciences and his master’s degree from ETH Zurich.</td></tr></table></Details>

  * <Details><summary>►Sungjoon Choi (Korea University, Korea)</summary><table width="100%"><tr><td width="25%"> <img src="../assets/images/sungjoon_choi.png" alt= "" width="300" style="vertical-align: left;"></td><td width="5%"></td><td width="70%" style="vertical-align: left; font-size: 75%;">Sungjoon Choi is presently an assistant professor at Korea University in the Department of Artificial Intelligence. He received Ph.D. in Electrical and Computer Engineering from Seoul National University (2018) and a B.S. degree in Electrical Engineering and Computer Science from Seoul National University (2012). Dr. Choi was a postdoc at Disney Research  Los Angeles, focussing on applying machine learning methods in robotics. Before joining Disney Research, he was a research scientist at Kakao Brain in Korea. His research interests include sample-efficient reinforcement learning and human-robot interaction, and received Best Conference Paper Finalist Award at the 2016 IEEE International Conference on Robotics and Automation (ICRA). </td></tr></table></Details>

  * <Details><summary>►Libin Liu (Peking University, China)</summary><table width="100%"><tr><td width="25%"> <img src="../assets/images/libin_liu.jpeg" alt= "" width="300" style="vertical-align: left;"></td><td width="5%"></td><td width="70%" style="vertical-align: left; font-size: 75%;">Dr. Libin Liu is an Assistant Professor at Peking University. Before joining Peking University, he was the Chief Scientist of DeepMotion Inc. and was a postdoc researcher at Disney Research and the University of British Columbia. Dr. Liu received his Ph.D. degree in computer science from Tsinghua University. His research interests include physics-based simulation, character animation, motion control, and broader areas such as reinforcement learning and deep learning. He served on the program committees of all the major computer graphics conferences, including ACM SIGGRAPH (North America/Asia), Pacific Graphics, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, etc.</td></tr></table></Details>

  * <Details><summary>►Michiel van de Panne (University of British Columbia, Canada)</summary><table width="100%"><tr><td width="25%"> <img src="../assets/images/michiel_van_de_panne.jpeg" alt= "" width="300" style="vertical-align: left;"></td><td width="5%"></td><td width="70%" style="vertical-align: left; font-size: 75%;">Michiel van de Panne‘s research interests are in deep reinforcement learning, physics-based animation of human and animal motion, learning for motor control, motion planning, robotics, and computer graphics. He is a co-founder of the ACM/Eurographics Symposium on Computer Animation, the leading forum focused on computer animation and simulation research.  He was awarded the 2022 ACMSIGGRAPH Computer Graphics Achievement Award, the 2016 CHCCS Achievement Award for his contributions to computer graphics, and held a Tier 2 Canada Research Chair during 2002-2011.  He currently serves as the deputy director of CAIDA, which is UBC's main AI organization.  He cofounded Motion Playground, the developer of the Ski Stunt Simulator game, one of the earliest games to be fully designed around physics-based game play.  His students and postdocs have (co)founded companies including Anomotion, VGC Software, Element AI, and Waverly; have assumed key roles at Tesla (director of AI and Autopilot vision), DeepMotion, and Electronic Arts, and nine are university faculty. He is a full professor in the Department of Computer Science at the University of British Columbia in Vancouver, Canada. Prior to moving to UBC, he was an Associate Professor in the Department of Computer Science at the University of Toronto</td></tr></table></Details>

  * <Details><summary>►Daniele Pucci (Italiano di Technologia, Italy)</summary>Biography</Details>

  * <Details><summary>►Eiichi Yoshida (Tokyo University of Science, Japan)</summary>Biography</Details>
  
  
### Program
##### Timelines are based on Korean Time (UTC+09:00). Click title to see abstract.
  * 13:20 ~ 13:30: Opening
  * <Details><summary>13:30 ~ 14:00: "Motion Imitation as a Useful Crutch:  Natural Movement for Animation and Robotics", Michiel van de Panne</summary><span style="font-size:15px">Abstract: The generation of purposeful and directable natural movement is a shared goal for animation and robotics. Computer animation methods have a long history of using motion capture data to produce high-quality kinematic motion. In contrast, for physics-based motion generation have long been split into two categories -- those that use motion capture data as a strong prior, and those that aim to generate the motion more directly from first principles. Currently, imitation of motion capture data leads to current state-of-the-art results, in motion quality, particularly when combined with reinforcement learning. However, I will argue that in the long term, imitation-based methods can be viewed as a convenient crutch while we develop better (and more directable) from-first-principles approaches. The belief here is that a combination of physics, compliant actuation, rich sensing, and highly-capable control ultimately underly natural motion.  We'll motivate these arguments with examples including brachiation, locomotion, high-jumps, getting up, and more.</span></Details>
  * <Details><summary>14:00 ~ 14:30: Robust Robot Motion Retargeting from RGB Videos, Sungjoon Choi</summary><span style="font-size:15px">Abstract: Generating natural and expressive robotic motions for humanoid robots has gained considerable interest from both robotics and computer graphics communities. Recently, this phenomenon has been accelerated by the fact that more human-like robots are permeating our daily lives through applications such as interactive services or educational robots. However, in order to generate a number of natural motions for humanoid robots, a substantial amount of effort is often required to design time-stamped robotic motions by animators or artists manually. In this talk, we focus on different approaches to generating diverse and natural robotic motions from multiple sources, including motion capture data and YouTube videos, while considering pose estimation errors. 
</span></Details>
  * 14:30 ~ 15:00: Invited Talk 3 (Eiichi Yoshida)
  * 15:00 ~ 15:30: Coffee Break
  * 15:30 ~ 16:00: Invited Talk 4 (Daniele Pucci)
  * <Details><summary>16:00 ~ 16:30: "Retargeting Motions onto Robotic Characters", Moritz Bächer</summary><span style="font-size:15px">Abstract: Legged robots or fixed-base robotic characters are built to perform highly dynamic motions. However, it remains challenging to retarget expressive motions onto these complex systems. In this talk, I will first discuss a versatile inverse kinematics to retarget artist-specified motion onto robotic systems with kinematic loops. I will then talk about a differentiable flexible multibody dynamics that enables us to retarget motions onto soft and lightweight robotic characters while suppressing vibrations. Finally, I will discuss a technique that permits the retargeting of motion capture data onto legged systems with a novel differentiable optimal control technique, accounting for differences in proportions and mass distribution of the source of input motion and the robot.</span></Details>
  * <Details><summary>16:30 ~ 17:00: "Go Beyond Imitation: Generative Representation and Control of Natural Movement", Libin Liu </summary><span style="font-size:15px">Abstract: Generating realistic behaviors is a fundamental challenge in computer animation and a critical technique in emerging fields such as digital humans and humanoid robots. Over the past years, there has been tremendous progress in this area, driven in part by advancements in deep learning and reinforcement learning. In this talk, I will introduce our recent work on developing multi-skilled characters capable of executing natural movements. I will provide a brief overview of early efforts using state machines and control snippet scheduling but will focus more on the utilization of more powerful generative models. Particularly, I will detail how variational autoencoders and their quantized versions serve as efficient and compact representations for motion. Additionally, I will explain how we manipulate these generative models to achieve fine-grained control over the produced motion. We utilize multi-modal inputs, such as text, imagery, video, and motion demonstration, to achieve precise control of motion details. This approach not only offers an intuitive interface for users to manipulate motion but also enables seamless integration with advanced AI systems like ChatGPT.</span></Details>
  * 17:00 ~ 17:10: Closing



<!-- 
### Program 
<table width="100%">
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> <b>Korean Time (UTC+09:00)</b></td>
    <td width="70%" style="text-align: center; vertical-align: left;"> <b>Schedule</b></td>
  </tr>  
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 13:20 ~ 13:30 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Opening </td>
  </tr> 
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 13:30 ~ 14:00 </td>
    <td width="70%" style="text-align: center; vertical-align: left;">

[Invited Talk 1 (Michiel van de Panne)](#invited-talk-1-michiel-van-de-panne)

  </td>
  </tr> 
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 14:00 ~ 14:30 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Invited Talk 2 (Sungjoon Choi) </td>
  </tr> 
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 14:30 ~ 15:00 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Invited Talk 3 (Eiichi Yoshida) </td>
  </tr>
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 15:00 ~ 15:30 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Coffee Break and Poster Session </td>
  </tr>
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 15:30 ~ 16:00 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Invited Talk 4 (Daniele Pucci) </td>
  </tr>
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 16:00 ~ 16:30 </td>
    <td width="70%" style="text-align: center; vertical-align: left;">
    Invited Talk 5 (Moritz Bächer)
    </td>
  </tr>
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 16:30 ~ 17:00 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Invited Talk 6 (Libin Liu) </td>
  </tr>
  <tr>
    <td width="50%" style="text-align: center; vertical-align: left;"> 17:00 ~ 17:10 </td>
    <td width="50%" style="text-align: center; vertical-align: left;"> Closing </td>
  </tr>
</table>

### Abstract 
##### Invited Talk 1 (Michiel van de Panne)

##### Invited Talk 2 (Sungjoon Choi)

##### Invited Talk 3 (Eiichi Yoshida)

##### Invited Talk 4 (Daniele Pucci)

##### Invited Talk 5 (Moritz Bächer)

##### Invited Talk 6 (Libin Liu) -->