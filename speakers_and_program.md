---
title: Speakers and Program
indexing: false
sitemap: false
---
### Invited Speakers

##### Alphabetical order on surname.
##### Click name for Biography.
  * <Details><summary>Moritz Bächer (Disney Research, Switzerland)</summary><table width="100%"><tr><td width="25%"> <img src="../assets/images/moritz_baecher.jpeg" alt= "" width="300" style="vertical-align: left;"></td><td width="5%"></td><td width="70%" style="vertical-align: left; font-size: 75%;"> Moritz Bächer is the Associate Lab Director of Disney Research at Walt Disney Imagineering, where he leads a strategic program focusing on the development of novel model- and learning-based tools for the design and control of believable robotic characters. His core expertise is the optimal design and control of both soft and rigid systems, using a combination of differentiable simulation and reinforcement learning. Prior to joining Disney, he received his Ph.D. from the Harvard School of Engineering and Applied Sciences and his master’s degree from ETH Zurich.</td></tr></table></Details>

  * <Details><summary>Sungjoon Choi (Korea University, Korea)</summary><table width="100%"><tr><td width="25%"> <img src="../assets/images/sungjoon_choi.png" alt= "" width="300" style="vertical-align: left;"></td><td width="5%"></td><td width="70%" style="vertical-align: left; font-size: 75%;">Sungjoon Choi is presently an assistant professor at Korea University in the Department of Artificial Intelligence. He received Ph.D. in Electrical and Computer Engineering from Seoul National University (2018) and a B.S. degree in Electrical Engineering and Computer Science from Seoul National University (2012). Dr. Choi was a postdoc at Disney Research  Los Angeles, focussing on applying machine learning methods in robotics. Before joining Disney Research, he was a research scientist at Kakao Brain in Korea. His research interests include sample-efficient reinforcement learning and human-robot interaction, and received Best Conference Paper Finalist Award at the 2016 IEEE International Conference on Robotics and Automation (ICRA). </td></tr></table></Details>

  * <Details><summary>Libin Liu (Peking University, China)</summary><table width="100%"><tr><td width="25%"> <img src="../assets/images/libin_liu.jpeg" alt= "" width="300" style="vertical-align: left;"></td><td width="5%"></td><td width="70%" style="vertical-align: left; font-size: 75%;">Dr. Libin Liu is an Assistant Professor at Peking University. Before joining Peking University, he was the Chief Scientist of DeepMotion Inc. and was a postdoc researcher at Disney Research and the University of British Columbia. Dr. Liu received his Ph.D. degree in computer science from Tsinghua University. His research interests include physics-based simulation, character animation, motion control, and broader areas such as reinforcement learning and deep learning. He served on the program committees of all the major computer graphics conferences, including ACM SIGGRAPH (North America/Asia), Pacific Graphics, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, etc.</td></tr></table></Details>

  * <Details><summary>Michiel van de Panne (University of British Columbia, Canada)</summary><table width="100%"><tr><td width="25%"> <img src="../assets/images/michiel_van_de_panne.jpeg" alt= "" width="300" style="vertical-align: left;"></td><td width="5%"></td><td width="70%" style="vertical-align: left; font-size: 75%;">Michiel van de Panne‘s research interests are in deep reinforcement learning, physics-based animation of human and animal motion, learning for motor control, motion planning, robotics, and computer graphics. He is a co-founder of the ACM/Eurographics Symposium on Computer Animation, the leading forum focused on computer animation and simulation research.  He was awarded the 2022 ACMSIGGRAPH Computer Graphics Achievement Award, the 2016 CHCCS Achievement Award for his contributions to computer graphics, and held a Tier 2 Canada Research Chair during 2002-2011.  He currently serves as the deputy director of CAIDA, which is UBC's main AI organization.  He cofounded Motion Playground, the developer of the Ski Stunt Simulator game, one of the earliest games to be fully designed around physics-based game play.  His students and postdocs have (co)founded companies including Anomotion, VGC Software, Element AI, and Waverly; have assumed key roles at Tesla (director of AI and Autopilot vision), DeepMotion, and Electronic Arts, and nine are university faculty. He is a full professor in the Department of Computer Science at the University of British Columbia in Vancouver, Canada. Prior to moving to UBC, he was an Associate Professor in the Department of Computer Science at the University of Toronto</td></tr></table></Details>

  * <Details><summary>Daniele Pucci (Italiano di Technologia, Italy)</summary><table width="100%"><tr><td width="25%"><img src="../assets/images/daniele_pucci.jpeg" alt= "" width="300" style="vertical-align: left;"></td><td width="5%"></td><td width="70%" style="vertical-align: left; font-size: 75%;">Daniele received the bachelor and master degrees in Control Engineering with highest honors from ”Sapienza”, University of Rome, in 2007 and 2009, respectively. In 2013, he earned the PhD title with a thesis prepared at INRIA Sophia Antipolis, France, with the supervision of Tarek Hamel, Salvatore Monaco, and Claude Samson. From 2013 to 2017, he has been a postdoc at the Istituto Italiano di Tecnologia (IIT) working within the EU project CoDyCo focusing on the balancing problem of the iCub humanoid robot. From August 2017 to August 2021, he has been the head of the Dynamic Interaction Control lab, a group of about 20 members focusing on the iCub locomotion walking problem. In this period, Daniele also laid the basis for the "Aerial Humanoid Robotics", a new branch of Robotics whose main aim is to achieve flying humanoid robots. Daniele has also been the scientific PI of the H2020 European Project AnDy, and now is: task leader of the H2020 European Project SoftManBot, coordinator of the joint laboratory between IIT and Honda JP, principal investigator (PI) in the Camozzi-IIT and Danieli Automation-IIT joint labs. Lastly, Daniele is the coordinator of the ergoCub project, a 5 million, three year joint project between INAIL and IIT.  Since September 2021, Daniele is the PI leading the  Artificial and Mechanical Intelligence  research line at IIT, a team composed of about forty members that combines AI and Mechanics to devise the next generation of the iCub humanoid robot. </td></tr></table></Details>

  * <Details><summary>Eiichi Yoshida (Tokyo University of Science, Japan)</summary><table width="100%"><tr><td width="25%"><img src="../assets/images/eiichi_yoshida.jpeg" alt= "" width="300" style="vertical-align: left;"></td><td width="5%"></td><td width="70%" style="vertical-align: left; font-size: 75%;">Eiichi Yoshida received M.E and Ph. D degrees on Precision Machinery Engineering from Graduate School of Engineering, the University of Tokyo in 1996. He then joined former Mechanical Engineering Laboratory, later in 2001 reorganized as National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan. He served as Co-Director of AIST-CNRS JRL (Joint Robotics Laboratory) at LAAS-CNRS, Toulouse, France, from 2004 to 2008, and at AIST, Tsukuba, Japan from 2009 to 2021. He was also Deputy Director of Industrial Cyber-Physical Systems Research Center, and TICO-AIST Cooperative Research Laboratory for Advanced Logistics in AIST from 2020 to 2021. In 2022 he moved to Tokyo University of Science (TUS), and is currently Professor at Department of Medical and Robotic Engineering Design, Faculty of Advanced Engineering of TUS. He is IEEE Fellow, and member of RSJ, SICE and JSME. He has published more than 200 scientific papers in journals and peer-reviewed international conferences and co-edited some books. He received several awards including Best Paper Award in Advance Robotics Journal and the honor of Chevalier l’Ordre National du Mérite from French Government. His research interests include robot task and motion planning, human modeling, humanoid robotics and advanced logistics technology.</td></tr></table></Details>
  
  
### Program
##### Timelines are based on Korean Time (UTC+09:00).
##### Click title to see abstract.
  * 13:20 ~ 13:30: Opening
  * 13:30 ~ 14:00: Invited Talk 1 (Michiel van de Panne)
    * <Details><summary>"Motion Imitation as a Useful Crutch:  Natural Movement for Animation and Robotics"</summary><span style="font-size:15px">Abstract: The generation of purposeful and directable natural movement is a shared goal for animation and robotics. Computer animation methods have a long history of using motion capture data to produce high-quality kinematic motion. In contrast, for physics-based motion generation have long been split into two categories -- those that use motion capture data as a strong prior, and those that aim to generate the motion more directly from first principles. Currently, imitation of motion capture data leads to current state-of-the-art results, in motion quality, particularly when combined with reinforcement learning. However, I will argue that in the long term, imitation-based methods can be viewed as a convenient crutch while we develop better (and more directable) from-first-principles approaches. The belief here is that a combination of physics, compliant actuation, rich sensing, and highly-capable control ultimately underly natural motion.  We'll motivate these arguments with examples including brachiation, locomotion, high-jumps, getting up, and more.</span></Details>
  * 14:00 ~ 14:30: Invited Talk 2 (Sungjoon Choi)
    * <Details><summary>"Robust Robot Motion Retargeting from RGB Videos"</summary><span style="font-size:15px">Abstract: Generating natural and expressive robotic motions for humanoid robots has gained considerable interest from both robotics and computer graphics communities. Recently, this phenomenon has been accelerated by the fact that more human-like robots are permeating our daily lives through applications such as interactive services or educational robots. However, in order to generate a number of natural motions for humanoid robots, a substantial amount of effort is often required to design time-stamped robotic motions by animators or artists manually. In this talk, we focus on different approaches to generating diverse and natural robotic motions from multiple sources, including motion capture data and YouTube videos, while considering pose estimation errors. 
</span></Details>
  * 14:30 ~ 15:00: Invited Talk 3 (Eiichi Yoshida)
    * <Details><summary>"Understanding, reproducing and synthesizing natural human motions"</summary><span style="font-size:15px">Abstract: Human-likeliness in motions is one of the critical topics in research on human-robot interaction and also biomechanics. In this presentation, I will address human motion reproduction by humanoid robots and its application to evaluation of wearable assistive device. To what extent can we make the humanoid motions as close as humans' considering intrinsic difference in structure and actuation between humans and robots? We believe posing this question is helpful for natural motion understanding. In our approach, we formulated this question as an optimization problem of motion similarity, incorporating geometric morphing and constraints of the human and humanoid. Although there are still hardware limitation, we could retarget various human motions to a humanoid motions. By extracting specific feature of hip and knee motions of a lifting task, we contributed to standardization of wearable lumbar support robots. However, reproduction of human motion is halfway to the natural motion "generation": ultimately we aim at predicting, or synthesizing natural motions for anthropomorphic systems. Having this challenge in mind, I introduce recent an ongoing project focusing on analysis and synthesis of contact motions. Some preliminary results are reported on contact estimation from  motion only by using machine learning.
 </span></Details>
  * 15:00 ~ 15:30: Coffee Break
  * 15:30 ~ 16:00: Invited Talk 4 (Daniele Pucci)
    * <Details><summary>"Towards Human-Like Motion Generation for Humanoid Robots"</summary><span style="font-size:15px">Humanoid robots are floating base systems that resemble the human shape. So, the natural question when trying to generate trajectories for these systems is to get a degree of human likeness, although this may not be a necessary condition for the problem of trajectory generation for the system itself. This talk will present trajectory-optimisation, supervised learning, and reinforcement learning  techniques for generating motions of humanoid robots with a degree of human likeness. </span></Details>
  * 16:00 ~ 16:30: Invited Talk 5 (Moritz Bächer)
    * <Details><summary>"Retargeting Motions onto Robotic Characters"</summary><span style="font-size:15px">Abstract: Legged robots or fixed-base robotic characters are built to perform highly dynamic motions. However, it remains challenging to retarget expressive motions onto these complex systems. In this talk, I will first discuss a versatile inverse kinematics to retarget artist-specified motion onto robotic systems with kinematic loops. I will then talk about a differentiable flexible multibody dynamics that enables us to retarget motions onto soft and lightweight robotic characters while suppressing vibrations. Finally, I will discuss a technique that permits the retargeting of motion capture data onto legged systems with a novel differentiable optimal control technique, accounting for differences in proportions and mass distribution of the source of input motion and the robot.</span></Details>
  
  * 16:30 ~ 17:00: Invited Talk 6 (Libin Liu)
    * <Details><summary>"Go Beyond Imitation: Generative Representation and Control of Natural Movement"</summary><span style="font-size:15px">Abstract: Generating realistic behaviors is a fundamental challenge in computer animation and a critical technique in emerging fields such as digital humans and humanoid robots. Over the past years, there has been tremendous progress in this area, driven in part by advancements in deep learning and reinforcement learning. In this talk, I will introduce our recent work on developing multi-skilled characters capable of executing natural movements. I will provide a brief overview of early efforts using state machines and control snippet scheduling but will focus more on the utilization of more powerful generative models. Particularly, I will detail how variational autoencoders and their quantized versions serve as efficient and compact representations for motion. Additionally, I will explain how we manipulate these generative models to achieve fine-grained control over the produced motion. We utilize multi-modal inputs, such as text, imagery, video, and motion demonstration, to achieve precise control of motion details. This approach not only offers an intuitive interface for users to manipulate motion but also enables seamless integration with advanced AI systems like ChatGPT.</span></Details>
  * 17:00 ~ 17:10: Closing



<!-- 
### Program 
<table width="100%">
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> <b>Korean Time (UTC+09:00)</b></td>
    <td width="70%" style="text-align: center; vertical-align: left;"> <b>Schedule</b></td>
  </tr>  
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 13:20 ~ 13:30 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Opening </td>
  </tr> 
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 13:30 ~ 14:00 </td>
    <td width="70%" style="text-align: center; vertical-align: left;">

[Invited Talk 1 (Michiel van de Panne)](#invited-talk-1-michiel-van-de-panne)

  </td>
  </tr> 
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 14:00 ~ 14:30 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Invited Talk 2 (Sungjoon Choi) </td>
  </tr> 
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 14:30 ~ 15:00 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Invited Talk 3 (Eiichi Yoshida) </td>
  </tr>
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 15:00 ~ 15:30 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Coffee Break and Poster Session </td>
  </tr>
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 15:30 ~ 16:00 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Invited Talk 4 (Daniele Pucci) </td>
  </tr>
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 16:00 ~ 16:30 </td>
    <td width="70%" style="text-align: center; vertical-align: left;">
    Invited Talk 5 (Moritz Bächer)
    </td>
  </tr>
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 16:30 ~ 17:00 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Invited Talk 6 (Libin Liu) </td>
  </tr>
  <tr>
    <td width="50%" style="text-align: center; vertical-align: left;"> 17:00 ~ 17:10 </td>
    <td width="50%" style="text-align: center; vertical-align: left;"> Closing </td>
  </tr>
</table>

### Abstract 
##### Invited Talk 1 (Michiel van de Panne)

##### Invited Talk 2 (Sungjoon Choi)

##### Invited Talk 3 (Eiichi Yoshida)

##### Invited Talk 4 (Daniele Pucci)

##### Invited Talk 5 (Moritz Bächer)

##### Invited Talk 6 (Libin Liu) -->