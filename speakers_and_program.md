---
title: Speakers and Program
indexing: false
sitemap: false
---
### Invited Speakers

##### Alphabetical order on surname (Click name for Biography)   
  * <Details><summary>Moritz Bächer (Disney Research, Switzerland)</summary><table width="100%"><tr><td width="25%"> <img src="../assets/images/moritz_baecher.jpeg" alt= "" width="300" style="vertical-align: left;"></td><td width="5%"></td><td width="70%" style="vertical-align: left; font-size: 75%;"> Moritz Bächer is the Associate Lab Director of Disney Research at Walt Disney Imagineering, where he leads a strategic program focusing on the development of novel model- and learning-based tools for the design and control of believable robotic characters. His core expertise is the optimal design and control of both soft and rigid systems, using a combination of differentiable simulation and reinforcement learning. Prior to joining Disney, he received his Ph.D. from the Harvard School of Engineering and Applied Sciences and his master’s degree from ETH Zurich.</td></tr></table></Details>

  * <Details><summary>Sungjoon Choi (Korea University, Korea)</summary><table width="100%"><tr><td width="25%"> <img src="../assets/images/sungjoon_choi.png" alt= "" width="300" style="vertical-align: left;"></td><td width="5%"></td><td width="70%" style="vertical-align: left; font-size: 75%;">Sungjoon Choi is presently an assistant professor at Korea University in the Department of Artificial Intelligence. He received Ph.D. in Electrical and Computer Engineering from Seoul National University (2018) and a B.S. degree in Electrical Engineering and Computer Science from Seoul National University (2012). Dr. Choi was a postdoc at Disney Research  Los Angeles, focussing on applying machine learning methods in robotics. Before joining Disney Research, he was a research scientist at Kakao Brain in Korea. His research interests include sample-efficient reinforcement learning and human-robot interaction, and received Best Conference Paper Finalist Award at the 2016 IEEE International Conference on Robotics and Automation (ICRA). </td></tr></table></Details>

  * <Details><summary>Libin Liu (Peking University, China)</summary><table width="100%"><tr><td width="25%"> <img src="../assets/images/libin_liu.jpeg" alt= "" width="300" style="vertical-align: left;"></td><td width="5%"></td><td width="70%" style="vertical-align: left; font-size: 75%;">Dr. Libin Liu is an Assistant Professor at Peking University. Before joining Peking University, he was the Chief Scientist of DeepMotion Inc. and was a postdoc researcher at Disney Research and the University of British Columbia. Dr. Liu received his Ph.D. degree in computer science from Tsinghua University. His research interests include physics-based simulation, character animation, motion control, and broader areas such as reinforcement learning and deep learning. He served on the program committees of all the major computer graphics conferences, including ACM SIGGRAPH (North America/Asia), Pacific Graphics, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, etc.</td></tr></table></Details>

  * <Details><summary>Michiel van de Panne (University of British Columbia, Canada)</summary>Biography</Details>

  * <Details><summary>Daniele Pucci (Italiano di Technologia, Italy)</summary>Biography</Details>

  * <Details><summary>Eiichi Yoshida (Tokyo University of Science, Japan)</summary>Biography</Details>
  
  
### Program
##### Timelines are based on Korean Time (UTC+09:00). Click to see abstract.
  * 13:20 ~ 13:30: Opening
  * 13:30 ~ 14:00: Invited Talk 1 (Michiel van de Panne)
  * <Details><summary>14:00 ~ 14:30: Robust Robot Motion Retargeting from RGB Videos (Sungjoon Choi)</summary><span style="font-size:13px">Abstract: Generating natural and expressive robotic motions for humanoid robots has gained considerable interest from both robotics and computer graphics communities. Recently, this phenomenon has been accelerated by the fact that more human-like robots are permeating our daily lives through applications such as interactive services or educational robots. However, in order to generate a number of natural motions for humanoid robots, a substantial amount of effort is often required to design time-stamped robotic motions by animators or artists manually. In this talk, we focus on different approaches to generating diverse and natural robotic motions from multiple sources, including motion capture data and YouTube videos, while considering pose estimation errors. 
</span></Details>
  * 14:30 ~ 15:00: Invited Talk 3 (Eiichi Yoshida)
  * 15:00 ~ 15:30: Coffee Break
  * 15:30 ~ 16:00: Invited Talk 4 (Daniele Pucci)
  * <Details><summary>16:00 ~ 16:30: "Retargeting Motions onto Robotic Characters", Moritz Bächer</summary><span style="font-size:13px">Abstract: Legged robots or fixed-base robotic characters are built to perform highly dynamic motions. However, it remains challenging to retarget expressive motions onto these complex systems. In this talk, I will first discuss a versatile inverse kinematics to retarget artist-specified motion onto robotic systems with kinematic loops. I will then talk about a differentiable flexible multibody dynamics that enables us to retarget motions onto soft and lightweight robotic characters while suppressing vibrations. Finally, I will discuss a technique that permits the retargeting of motion capture data onto legged systems with a novel differentiable optimal control technique, accounting for differences in proportions and mass distribution of the source of input motion and the robot.</span></Details>
  * <Details><summary>16:30 ~ 17:00: "Go Beyond Imitation: Generative Representation and Control of Natural Movement", Libin Liu </summary><span style="font-size:13px">Abstract: Generating realistic behaviors is a fundamental challenge in computer animation and a critical technique in emerging fields such as digital humans and humanoid robots. Over the past years, there has been tremendous progress in this area, driven in part by advancements in deep learning and reinforcement learning. In this talk, I will introduce our recent work on developing multi-skilled characters capable of executing natural movements. I will provide a brief overview of early efforts using state machines and control snippet scheduling but will focus more on the utilization of more powerful generative models. Particularly, I will detail how variational autoencoders and their quantized versions serve as efficient and compact representations for motion. Additionally, I will explain how we manipulate these generative models to achieve fine-grained control over the produced motion. We utilize multi-modal inputs, such as text, imagery, video, and motion demonstration, to achieve precise control of motion details. This approach not only offers an intuitive interface for users to manipulate motion but also enables seamless integration with advanced AI systems like ChatGPT.</span></Details>
  * 17:00 ~ 17:10: Closing



<!-- 
### Program 
<table width="100%">
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> <b>Korean Time (UTC+09:00)</b></td>
    <td width="70%" style="text-align: center; vertical-align: left;"> <b>Schedule</b></td>
  </tr>  
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 13:20 ~ 13:30 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Opening </td>
  </tr> 
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 13:30 ~ 14:00 </td>
    <td width="70%" style="text-align: center; vertical-align: left;">

[Invited Talk 1 (Michiel van de Panne)](#invited-talk-1-michiel-van-de-panne)

  </td>
  </tr> 
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 14:00 ~ 14:30 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Invited Talk 2 (Sungjoon Choi) </td>
  </tr> 
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 14:30 ~ 15:00 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Invited Talk 3 (Eiichi Yoshida) </td>
  </tr>
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 15:00 ~ 15:30 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Coffee Break and Poster Session </td>
  </tr>
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 15:30 ~ 16:00 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Invited Talk 4 (Daniele Pucci) </td>
  </tr>
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 16:00 ~ 16:30 </td>
    <td width="70%" style="text-align: center; vertical-align: left;">
    Invited Talk 5 (Moritz Bächer)
    </td>
  </tr>
  <tr>
    <td width="30%" style="text-align: center; vertical-align: left;"> 16:30 ~ 17:00 </td>
    <td width="70%" style="text-align: center; vertical-align: left;"> Invited Talk 6 (Libin Liu) </td>
  </tr>
  <tr>
    <td width="50%" style="text-align: center; vertical-align: left;"> 17:00 ~ 17:10 </td>
    <td width="50%" style="text-align: center; vertical-align: left;"> Closing </td>
  </tr>
</table>

### Abstract 
##### Invited Talk 1 (Michiel van de Panne)

##### Invited Talk 2 (Sungjoon Choi)

##### Invited Talk 3 (Eiichi Yoshida)

##### Invited Talk 4 (Daniele Pucci)

##### Invited Talk 5 (Moritz Bächer)

##### Invited Talk 6 (Libin Liu) -->